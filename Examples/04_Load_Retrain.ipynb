{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a pretrained model and keep training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "from jax import random, numpy as jnp\n",
    "import flax\n",
    "from flax.training import orbax_utils\n",
    "import optax\n",
    "import orbax\n",
    "import orbax.checkpoint\n",
    "\n",
    "from paramperceptnet.models import PerceptNet\n",
    "from paramperceptnet.training import create_train_state, pearson_correlation, train_step, compute_metrics\n",
    "from paramperceptnet.constraints import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a set of pretrained weights\n",
    "\n",
    "Currently, the weights are stored in W&B (they will be in HF at some point), so we have to download them before putting them into our model.\n",
    "The good part is that the configuration is stored along the weights, so we don't need to load them separatelly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from ml_collections import ConfigDict\n",
    "\n",
    "id = \"2ploco2u\"\n",
    "\n",
    "api = wandb.Api()\n",
    "run = api.run(f\"jorgvt/PerceptNet_v15/{id}\")\n",
    "save_path = f\"./{id}/\"\n",
    "\n",
    "try:\n",
    "    config = ConfigDict(run.config[\"_fields\"])\n",
    "except:\n",
    "    config = ConfigDict(run.config)\n",
    "\n",
    "for file in run.files():\n",
    "    file.download(root=save_path, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare `TrainState` & load a `state`\n",
    "\n",
    "In other examples we omited the existence of the `TrainState` to eliminate complexity but it can be really handy when we want to train our model because it holds the parameters, the state, the optimizer and its parameteres and the metrics of interest. This makes it very easy to continue training an already trained model because we provide the whole state.\n",
    "\n",
    "When training the model we employ a `optax.multi_transform` optimizer to be able to set some parameters to non-trainable. Because of this, if we want to load the same `TrainState` we have to define the same optimizer here (if the optimizers are different `optax` won't load the state). Another option would be loading the state as a python `dict` and then putting the loaded parameters and states into our `TrainState`. This would allow us to change the optimizer.\n",
    "\n",
    "Let's define it and load a pretrained one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(PerceptNet(config), key=random.PRNGKey(42), tx=optax.adam(3e-4), input_shape=(1,384,512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trainable(path):                                                                                                                           \n",
    "    if not config.A_GDNSPATIOFREQORIENT:                                                                                                             \n",
    "        if (\"GDNSpatioChromaFreqOrient_0\" in path) and (\"A\" in path):                                                                                \n",
    "            return True                                                                                                                              \n",
    "    if \"Color\" in path:                                                                                                                              \n",
    "        if not config.TRAIN_JH:                                                                                                                      \n",
    "            return True                                                                                                                              \n",
    "    if \"CenterSurroundLogSigmaK_0\" in path:                                                                                                          \n",
    "        if not config.TRAIN_CS:                                                                                                                      \n",
    "            return True                                                                                                                              \n",
    "    if \"Gabor\" in \"\".join(path):                                                                                                                     \n",
    "        if not config.TRAIN_GABOR:                                                                                                                   \n",
    "            return True                                                                                                                              \n",
    "    if \"GDNSpatioChromaFreqOrient_0\" not in path and config.TRAIN_ONLY_LAST_GDN:                                                                     \n",
    "        return True                                                                                                                                  \n",
    "    return False                                                                                                                                     \n",
    "                                                                                                                                                     \n",
    "trainable_tree = flax.core.freeze(flax.traverse_util.path_aware_map(lambda path, v: \"non_trainable\" if check_trainable(path)  else \"trainable\", state.params)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {                                         \n",
    "    \"trainable\": optax.adam(learning_rate=config.LEARNING_RATE),                                   \n",
    "    \"non_trainable\": optax.set_to_zero(),              \n",
    "}                                                      \n",
    "tx = optax.multi_transform(optimizers, trainable_tree) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(PerceptNet(config), key=random.PRNGKey(42), tx=tx, input_shape=(1,384,512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "save_args = orbax_utils.save_args_from_target(state)\n",
    "\n",
    "state = orbax_checkpointer.restore(os.path.join(save_path,\"model-best\"), item=state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss and `train_step`\n",
    "\n",
    "Both the loss function (pearson correlation) and `train_step` function are provided in `paramperceptnet.training`, but we will explicitly define here as well for completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_correlation(vec1, vec2):                    \n",
    "    vec1 = vec1.squeeze()                               \n",
    "    vec2 = vec2.squeeze()                               \n",
    "    vec1_mean = vec1.mean()                             \n",
    "    vec2_mean = vec2.mean()                             \n",
    "    num = vec1 - vec1_mean                              \n",
    "    num *= vec2 - vec2_mean                             \n",
    "    num = num.sum()                                     \n",
    "    denom = jnp.sqrt(jnp.sum((vec1 - vec1_mean) ** 2))  \n",
    "    denom *= jnp.sqrt(jnp.sum((vec2 - vec2_mean) ** 2)) \n",
    "    return num / denom                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnums=2)                                             \n",
    "def train_step(state, batch, return_grads=False):                               \n",
    "    \"\"\"Train for a single step.\"\"\"                                              \n",
    "    img, img_dist, mos = batch                                                  \n",
    "                                                                                \n",
    "    def loss_fn(params):                                                        \n",
    "        ##Â Forward pass through the model                                       \n",
    "        img_pred, updated_state = state.apply_fn(                               \n",
    "            {\"params\": params, **state.state},                                  \n",
    "            img,                                                                \n",
    "            mutable=list(state.state.keys()),                                   \n",
    "            train=True,                                                         \n",
    "        )                                                                       \n",
    "        img_dist_pred, updated_state = state.apply_fn(                          \n",
    "            {\"params\": params, **state.state},                                  \n",
    "            img_dist,                                                           \n",
    "            mutable=list(state.state.keys()),                                   \n",
    "            train=True,                                                         \n",
    "        )                                                                       \n",
    "                                                                                \n",
    "        ##Â Calculate the distance                                               \n",
    "        dist = ((img_pred - img_dist_pred) ** 2).sum(axis=(1, 2, 3)) ** (1 / 2) \n",
    "                                                                                \n",
    "        ##Â Calculate pearson correlation                                        \n",
    "        return pearson_correlation(dist, mos), updated_state                    \n",
    "                                                                                \n",
    "    (loss, updated_state), grads = jax.value_and_grad(loss_fn, has_aux=True)(   \n",
    "        state.params                                                            \n",
    "    )                                                                           \n",
    "    state = state.apply_gradients(grads=grads)                                  \n",
    "    metrics_updates = state.metrics.single_from_model_output(loss=loss)         \n",
    "    metrics = state.metrics.merge(metrics_updates)                              \n",
    "    state = state.replace(metrics=metrics)                                      \n",
    "    state = state.replace(state=updated_state)                                  \n",
    "    if return_grads:                                                            \n",
    "        return state, grads                                                     \n",
    "    else:                                                                       \n",
    "        return state                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit                                                                                                                                          \n",
    "def compute_metrics(*, state, batch):                                                                                                             \n",
    "    \"\"\"Obtaining the metrics for a given batch.\"\"\"                                                                                                \n",
    "    img, img_dist, mos = batch                                                                                                                    \n",
    "    def loss_fn(params):                                                                                                                          \n",
    "        ##Â Forward pass through the model                                                                                                         \n",
    "        img_pred, updated_state = state.apply_fn({\"params\": params, **state.state}, img, mutable=list(state.state.keys()), train=False)           \n",
    "        img_dist_pred, updated_state = state.apply_fn({\"params\": params, **state.state}, img_dist, mutable=list(state.state.keys()), train=False) \n",
    "                                                                                                                                                  \n",
    "        ##Â Calculate the distance                                                                                                                 \n",
    "        dist = ((img_pred - img_dist_pred)**2).sum(axis=(1,2,3))**(1/2)                                                                           \n",
    "                                                                                                                                                  \n",
    "        ##Â Calculate pearson correlation                                                                                                          \n",
    "        return pearson_correlation(dist, mos)                                                                                                     \n",
    "                                                                                                                                                  \n",
    "    metrics_updates = state.metrics.single_from_model_output(loss=loss_fn(state.params))                                                          \n",
    "    metrics = state.metrics.merge(metrics_updates)                                                                                                \n",
    "    state = state.replace(metrics=metrics)                                                                                                        \n",
    "    return state                                                                                                                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting some data\n",
    "\n",
    "We will fetch the TID2008 dataset from HuggingFace as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 276 ms, sys: 21.6 ms, total: 298 ms\n",
      "Wall time: 5.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = load_dataset(\"Jorgvt/TID2008\", num_proc=8, trust_remote_code=True)\n",
    "dataset = dataset.with_format(\"jax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_train = dataset[\"train\"]\n",
    "dst_train_rdy = dst_train.iter(batch_size=config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a simple training loop\n",
    "\n",
    "With both of these functions defined, we can write a simple training loop example. Notice we are clipping some of the parameters after every update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_history = {   \n",
    "    \"train_loss\": [], \n",
    "    \"val_loss\": [],   \n",
    "}                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(config.EPOCHS):                                                                                                                             \n",
    "    ## Training                                                                                                                                                \n",
    "    for batch in dst_train_rdy:                                                                                                            \n",
    "        batch = (batch[\"reference\"]/255., batch[\"distorted\"]/255., batch[\"mos\"])\n",
    "        state, grads = train_step(state, batch, return_grads=True)                                                                                             \n",
    "        state = state.replace(params=clip_layer(state.params, \"GDN\", a_min=0))                                                                                 \n",
    "        state = state.replace(params=clip_param(state.params, \"A\", a_min=0))                                                                                   \n",
    "        state = state.replace(params=clip_param(state.params, \"K\", a_min=1+1e-5))                                                                              \n",
    "        break\n",
    "                                                                                                                                                               \n",
    "    ## Log the metrics                                                                                                                                         \n",
    "    for name, value in state.metrics.compute().items():                                                                                                        \n",
    "        metrics_history[f\"train_{name}\"].append(value)                                                                                                         \n",
    "                                                                                                                                                               \n",
    "    ##Â Empty the metrics                                                                                                                                       \n",
    "    state = state.replace(metrics=state.metrics.empty())                                                                                                       \n",
    "                                                                                                                                                               \n",
    "    ## Evaluation                                                                                                                                              \n",
    "    for batch in dst_train_rdy:                                                                                                              \n",
    "        batch = (batch[\"reference\"]/255., batch[\"distorted\"]/255., batch[\"mos\"])\n",
    "        state = compute_metrics(state=state, batch=batch)                                                                                                      \n",
    "        break\n",
    "\n",
    "    for name, value in state.metrics.compute().items():                                                                                                        \n",
    "        metrics_history[f\"val_{name}\"].append(value)                                                                                                           \n",
    "    state = state.replace(metrics=state.metrics.empty())                                                                                                       \n",
    "                                                                                                                                                               \n",
    "    ##Â Checkpointing                                                                                                                                           \n",
    "    if metrics_history[\"val_loss\"][-1] <= min(metrics_history[\"val_loss\"]):                                                                                    \n",
    "        orbax_checkpointer.save(os.path.join(wandb.run.dir, \"model-best\"), state, save_args=save_args, force=True) # force=True means allow overwritting.      \n",
    "                                                                                                                                                               \n",
    "    print(f'Epoch {epoch} -> [Train] Loss: {metrics_history[\"train_loss\"][-1]} [Val] Loss: {metrics_history[\"val_loss\"][-1]}')                                 \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
